{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c2282e-c165-42ca-ad7d-3a5fcfc307c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755d039-9d06-4d42-85a2-61243a30e4f9",
   "metadata": {},
   "source": [
    "# Including Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eaa1be-6073-4325-ae73-dcd079a85b45",
   "metadata": {},
   "source": [
    "``AUCMEDI`` allows us to include metadata. This is useful, because it might be, that we have some additional information alongside our images such as age or blood values that have some value for classification.  \n",
    "\n",
    "We don't have such additional metadata for the dataset used here (images of colorectal cancer histology), but we will make some up for demonstation purposes.  \n",
    "\n",
    "But fist, the data need to be loaded.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d88c76c-1c45-4091-ae1c-2c6a5a8ca137",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Downloading and preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b09e9-2b07-4e63-a642-66b70880e771",
   "metadata": {},
   "source": [
    "First, the data need to be loaded and prepared for ``AUCMEDI``.  \n",
    "If you have questions concering that part, just have a look in the corresponding notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14d74b94-c62d-4d23-8a8f-c794ef4d87e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 09:43:43.506665: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "cwd = !pwd\n",
    "datadir = cwd[0] + \"/data\"\n",
    "Path(datadir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#print('Beginning file download with wget module')\n",
    "\n",
    "#url = 'https://zenodo.org/record/53169/files/Kather_texture_2016_image_tiles_5000.zip?download=1'\n",
    "#wget.download(url, datadir)\n",
    "\n",
    "#with zipfile.ZipFile(\"data/Kather_texture_2016_image_tiles_5000.zip\",\"r\") as zip_ref:\n",
    "#    zip_ref.extractall(\"data\")\n",
    "\n",
    "from aucmedi.data_processing.io_data import input_interface\n",
    "ds_loader = input_interface(\"directory\", path_imagedir=\"data/Kather_texture_2016_image_tiles_5000\", path_data=None, training=True, ohe=False)\n",
    "(samples, class_ohe, nclasses, class_names, image_format) = ds_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8381e5d-7360-4eba-9a37-3d088bef4fdc",
   "metadata": {},
   "source": [
    "## Generating Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afe3f41-827a-47d9-9fc6-60c37ae0ebb4",
   "metadata": {},
   "source": [
    "Now we will generate some random metadata. Of course they won't have value for classification, but we will see how to include the metadata into the ``AUCMEDI`` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1edbe4d3-1578-4d9f-a5d8-305c285eca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "age=random.randint(low=30, high=100, size=(5000))\n",
    "blood=random.randn(5000)\n",
    "metadata = np.vstack((age,blood)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aff2c4-0840-4baa-9899-0d230ce8ecdd",
   "metadata": {},
   "source": [
    "Let's see what our metadata looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cde45f2-4e4e-4774-a926-a41e99687c96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.50000000e+01,  1.23243337e-02],\n",
       "       [ 4.60000000e+01, -1.50783165e+00],\n",
       "       [ 4.80000000e+01, -4.62923412e-01],\n",
       "       ...,\n",
       "       [ 7.20000000e+01, -6.80484845e-01],\n",
       "       [ 4.40000000e+01, -2.83978910e-01],\n",
       "       [ 8.50000000e+01, -4.69024810e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41022f11-41f2-4aac-a2ed-0f9854f72420",
   "metadata": {},
   "source": [
    "So our metadata are a 2-dimensional numpy array with the dimensions (n_samples, n_variables).  \n",
    "In the first column are is the age and in the second column a blood-value of the samples (randomly generated).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ac6f1c-ed25-47f3-9c14-b716ef44a7c5",
   "metadata": {},
   "source": [
    "## Splitting our data in train-, test- and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729ecebb-0aac-463e-9470-076e28bcdc3e",
   "metadata": {},
   "source": [
    "When splitting the dataset with ``sampling_split`` we also include the metadata to the splitting (using the argument metadata) so that the metadata get split as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ee84d0d-d347-4f11-a692-5e30dcdc0f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aucmedi.sampling.split import sampling_split\n",
    "train, validation, test = sampling_split(samples, class_ohe, metadata=metadata, sampling=[0.5, 0.25, 0.25], \n",
    "                                         stratified=True, iterative=False, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5fe2050-77bf-470a-a5a6-a49bb4c65b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['07_ADIPOSE/15FFE_CRC-Prim-HE-03_012.tif_Row_1_Col_601.tif',\n",
       "        '01_TUMOR/10264_CRC-Prim-HE-07_025.tif_Row_1801_Col_1.tif',\n",
       "        '07_ADIPOSE/13CEE_CRC-Prim-HE-05_032.tif_Row_1501_Col_901.tif',\n",
       "        ..., '08_EMPTY/1470E_CRC-Prim-HE-06_005.tif_Row_4351_Col_2851.tif',\n",
       "        '07_ADIPOSE/14420_CRC-Prim-HE-10_020.tif_Row_601_Col_1801.tif',\n",
       "        '07_ADIPOSE/163E5_CRC-Prim-HE-06_004.tif_Row_1801_Col_451.tif'],\n",
       "       dtype='<U64'),\n",
       " array([[0, 0, 0, ..., 0, 1, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0]], dtype=uint8),\n",
       " array([[75.        ,  1.07417889],\n",
       "        [88.        , -1.0580301 ],\n",
       "        [90.        , -0.51070515],\n",
       "        ...,\n",
       "        [42.        ,  0.92283093],\n",
       "        [87.        ,  0.90734877],\n",
       "        [42.        ,  0.2433204 ]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035dc6e-66ec-4050-856f-3eb48facc667",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea1a78-aee5-474f-875c-a1ad9f506c90",
   "metadata": {},
   "source": [
    "Now we define our ``NeuralNetwork``. If you have questions concering that, have a look in the notebook \"Custom Architecture\" or \"3 Pillars\".  \n",
    "\n",
    "Importantly we have  to define the argument `meta_variables` as 2 here, so that AUCMEDI knows to include these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164f9815-d621-4b77-8435-97b67b01f1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 09:43:46.850717: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-27 09:43:47.419450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22844 MB memory:  -> device: 0, name: NVIDIA TITAN RTX, pci bus id: 0000:3f:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from aucmedi.neural_network.model import NeuralNetwork\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "f1Score = tfa.metrics.F1Score(num_classes=nclasses, threshold=0.5)\n",
    "\n",
    "model = NeuralNetwork(n_labels=nclasses, channels=3, \n",
    "                      loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\", f1Score], \n",
    "                      activation_output=\"softmax\", pretrained_weights=False, meta_variables = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f153af83-ac97-4c4d-9dda-69c99b337cc3",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e99e44e-1665-40fc-b91b-0797e3ba7d9d",
   "metadata": {},
   "source": [
    "Now, the model can be trained. If you have questions concering that, have a look at the notebook \"Costum Architecture\" or \"3 Pillars\".  \n",
    "\n",
    "Here, it is importatnt that we include the ``metadata`` for __each__ ``DataGenerator``. As you can see in the output above, the ``metadata`` for train, are in ``train[2]`` and accordingly the ``metadata`` for validation are in ``validation[2]``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c9dec3-8156-470d-b454-8cbe03db48cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 09:43:49.902739: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-07-27 09:43:50.476791: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 17s 179ms/step - loss: 3.3698 - categorical_accuracy: 0.1576 - f1_score: 0.1111 - val_loss: 1.7528 - val_categorical_accuracy: 0.2520 - val_f1_score: 0.1153\n",
      "Epoch 2/20\n",
      "79/79 [==============================] - 13s 165ms/step - loss: 1.9153 - categorical_accuracy: 0.2928 - f1_score: 0.2013 - val_loss: 1.4023 - val_categorical_accuracy: 0.4560 - val_f1_score: 0.2264\n",
      "Epoch 3/20\n",
      "79/79 [==============================] - 13s 163ms/step - loss: 1.6163 - categorical_accuracy: 0.3844 - f1_score: 0.2588 - val_loss: 1.3145 - val_categorical_accuracy: 0.5128 - val_f1_score: 0.2557\n",
      "Epoch 4/20\n",
      "79/79 [==============================] - 13s 162ms/step - loss: 1.4871 - categorical_accuracy: 0.4296 - f1_score: 0.3110 - val_loss: 1.1476 - val_categorical_accuracy: 0.5480 - val_f1_score: 0.2770\n",
      "Epoch 5/20\n",
      "79/79 [==============================] - 14s 172ms/step - loss: 1.2995 - categorical_accuracy: 0.4908 - f1_score: 0.3909 - val_loss: 1.0153 - val_categorical_accuracy: 0.6048 - val_f1_score: 0.3641\n",
      "Epoch 6/20\n",
      "79/79 [==============================] - 13s 167ms/step - loss: 1.2686 - categorical_accuracy: 0.5004 - f1_score: 0.4014 - val_loss: 1.0017 - val_categorical_accuracy: 0.5976 - val_f1_score: 0.3712\n",
      "Epoch 7/20\n",
      "79/79 [==============================] - 13s 166ms/step - loss: 1.1561 - categorical_accuracy: 0.5396 - f1_score: 0.4533 - val_loss: 0.9092 - val_categorical_accuracy: 0.6424 - val_f1_score: 0.4935\n",
      "Epoch 8/20\n",
      "79/79 [==============================] - 13s 158ms/step - loss: 1.0972 - categorical_accuracy: 0.5724 - f1_score: 0.4818 - val_loss: 0.8650 - val_categorical_accuracy: 0.6584 - val_f1_score: 0.4747\n",
      "Epoch 9/20\n",
      "79/79 [==============================] - 14s 173ms/step - loss: 1.0578 - categorical_accuracy: 0.5796 - f1_score: 0.4981 - val_loss: 0.8458 - val_categorical_accuracy: 0.6600 - val_f1_score: 0.5660\n",
      "Epoch 10/20\n",
      "79/79 [==============================] - 14s 170ms/step - loss: 1.0426 - categorical_accuracy: 0.5800 - f1_score: 0.5129 - val_loss: 0.7726 - val_categorical_accuracy: 0.6872 - val_f1_score: 0.5862\n",
      "Epoch 11/20\n",
      "79/79 [==============================] - 13s 169ms/step - loss: 0.9971 - categorical_accuracy: 0.6004 - f1_score: 0.5336 - val_loss: 0.7637 - val_categorical_accuracy: 0.7160 - val_f1_score: 0.6176\n",
      "Epoch 12/20\n",
      "79/79 [==============================] - 13s 168ms/step - loss: 0.9328 - categorical_accuracy: 0.6320 - f1_score: 0.5683 - val_loss: 0.7621 - val_categorical_accuracy: 0.7032 - val_f1_score: 0.6446\n",
      "Epoch 13/20\n",
      "79/79 [==============================] - 14s 170ms/step - loss: 0.8878 - categorical_accuracy: 0.6452 - f1_score: 0.5955 - val_loss: 0.7139 - val_categorical_accuracy: 0.7312 - val_f1_score: 0.6630\n",
      "Epoch 14/20\n",
      "79/79 [==============================] - 14s 170ms/step - loss: 0.8632 - categorical_accuracy: 0.6504 - f1_score: 0.6067 - val_loss: 0.7085 - val_categorical_accuracy: 0.7336 - val_f1_score: 0.6806\n",
      "Epoch 15/20\n",
      "79/79 [==============================] - 14s 171ms/step - loss: 0.8761 - categorical_accuracy: 0.6540 - f1_score: 0.6051 - val_loss: 0.6716 - val_categorical_accuracy: 0.7424 - val_f1_score: 0.6818\n",
      "Epoch 16/20\n",
      "79/79 [==============================] - 13s 169ms/step - loss: 0.8101 - categorical_accuracy: 0.6708 - f1_score: 0.6234 - val_loss: 0.6436 - val_categorical_accuracy: 0.7456 - val_f1_score: 0.7069\n",
      "Epoch 17/20\n",
      "79/79 [==============================] - 13s 170ms/step - loss: 0.8255 - categorical_accuracy: 0.6856 - f1_score: 0.6449 - val_loss: 0.6921 - val_categorical_accuracy: 0.7080 - val_f1_score: 0.6422\n",
      "Epoch 18/20\n",
      "79/79 [==============================] - 13s 168ms/step - loss: 0.7772 - categorical_accuracy: 0.6940 - f1_score: 0.6500 - val_loss: 0.6230 - val_categorical_accuracy: 0.7536 - val_f1_score: 0.7190\n",
      "Epoch 19/20\n",
      "79/79 [==============================] - 13s 161ms/step - loss: 0.7861 - categorical_accuracy: 0.6996 - f1_score: 0.6701 - val_loss: 0.6179 - val_categorical_accuracy: 0.7656 - val_f1_score: 0.7198\n",
      "Epoch 20/20\n",
      "79/79 [==============================] - 14s 171ms/step - loss: 0.7558 - categorical_accuracy: 0.7044 - f1_score: 0.6635 - val_loss: 0.6027 - val_categorical_accuracy: 0.7656 - val_f1_score: 0.7202\n"
     ]
    }
   ],
   "source": [
    "from aucmedi.data_processing.data_generator import DataGenerator\n",
    "\n",
    "train_generator = DataGenerator(samples=train[0], path_imagedir=\"data/Kather_texture_2016_image_tiles_5000\",\n",
    "                                               labels=train[1], metadata=train[2], resize=model.meta_input, \n",
    "                                               standardize_mode=model.meta_standardize, \n",
    "                                               image_format=image_format, batch_size=32, data_aug=None, \n",
    "                                               grayscale=False, subfunctions=[], prepare_images=False, \n",
    "                                               sample_weights=None, seed=123, workers=1)\n",
    "val_generator = DataGenerator(samples=validation[0], path_imagedir=\"data/Kather_texture_2016_image_tiles_5000\",\n",
    "                                               labels=validation[1], metadata=validation[2], resize=model.meta_input, \n",
    "                                               standardize_mode=model.meta_standardize, \n",
    "                                               image_format=image_format, batch_size=32, data_aug=None, \n",
    "                                               grayscale=False, subfunctions=[], prepare_images=False, \n",
    "                                               sample_weights=None, seed=123, workers=1)\n",
    "\n",
    "history = model.train(training_generator=train_generator, validation_generator=val_generator, epochs=20, iterations=None, \n",
    "                                         callbacks=None, class_weights=None, transfer_learning=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd27546-3a08-4230-8735-ff2aacf958e1",
   "metadata": {},
   "source": [
    "If you want to know how to evaluate the performance of your model, have a look in the corresponding notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
